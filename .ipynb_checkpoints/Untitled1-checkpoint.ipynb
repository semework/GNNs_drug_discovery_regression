{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "852564fb-7abb-47c3-8f92-5f3d2893871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "# !pip install ogb\n",
    "from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8b6f18b-ec3d-475c-8450-023be61b7fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 13:49:07.624718: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages.\n",
    "from torch_geometric.datasets import TUDataset, MoleculeNet\n",
    "import os\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import os.path as osp\n",
    "import torch_geometric\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import deepchem as dc\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid, MoleculeNet\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# transform = T.Compose([\n",
    "#     T.NormalizeFeatures(),\n",
    "#     T.ToDevice(device),\n",
    "#     T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "#                       add_negative_train_samples=False),\n",
    "# ])\n",
    "# dataset2 = Planetoid(root ='.', name='Cora', transform=transform)\n",
    "# train_data2, val_data2, test_data2 = dataset2[0]\n",
    "# dataset2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59feed66-1f15-4a10-b330-b5086f5696e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MoleculeNet.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38ebdb6b-b788-44b9-a9e3-61254060e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = MoleculeNet(root ='.', name='HIV' )\n",
    "# dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81606764-5381-47b8-921a-e54a90ed3cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[26, 9], edge_index=[2, 60], edge_attr=[60, 3], smiles='Cc1cccc(N2CCN(C(=O)C34CC5CC(CC(C5)C3)C4)CC2)c1C', y=[1, 17])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = MoleculeNet(root ='.', name='muv' )\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24025838-398e-4e43-acf7-b2826e8bad0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: MUV(93087):\n",
      "====================\n",
      "Number of graphs: 93087\n",
      "Number of features: 9\n",
      "Number of classes: 17\n",
      "\n",
      "Data(x=[26, 9], edge_index=[2, 60], edge_attr=[60, 3], smiles='Cc1cccc(N2CCN(C(=O)C34CC5CC(CC(C5)C3)C4)CC2)c1C', y=[1, 17])\n",
      "=============================================================\n",
      "Number of nodes: 26\n",
      "Number of edges: 60\n",
      "Average node degree: 2.31\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "# dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n",
    "# dataset =  MoleculeNet(root='.', name='SIDER')\n",
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d2a1d8b-b554-444e-82ff-906ee6ed4202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_index = torch.Size([2, 60])\n",
      "tensor([[ 0,  1,  1,  1,  2,  2,  3,  3,  4,  4,  5,  5,  5,  6,  6,  6,  7,  7,\n",
      "          8,  8,  9,  9,  9, 10, 10, 10, 11, 12, 12, 12, 12, 13, 13, 14, 14, 14,\n",
      "         15, 15, 16, 16, 16, 17, 17, 18, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22,\n",
      "         23, 23, 24, 24, 24, 25],\n",
      "        [ 1,  0,  2, 24,  1,  3,  2,  4,  3,  5,  4,  6, 24,  5,  7, 23,  6,  8,\n",
      "          7,  9,  8, 10, 22,  9, 11, 12, 10, 10, 13, 20, 21, 12, 14, 13, 15, 19,\n",
      "         14, 16, 15, 17, 21, 16, 18, 17, 19, 20, 14, 18, 12, 18, 12, 16,  9, 23,\n",
      "          6, 22,  1,  5, 25, 24]])\n"
     ]
    }
   ],
   "source": [
    "print(f'edge_index = {data.edge_index.shape}')\n",
    "print(data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45f82847-c904-4718-9e21-77f7e72bd0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = (26, 26)\n",
      "[[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "A = to_dense_adj(data.edge_index)[0].numpy().astype(int)\n",
    "print(f'A = {A.shape}')\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3f94de5-206c-4931-96ea-a4c4b7ca99b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = torch.Size([1, 17])\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, 0., nan, nan, nan, 0., nan, nan, nan, nan, nan]])\n"
     ]
    }
   ],
   "source": [
    "print(f'y = {data.y.shape}')\n",
    "print(data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "152a4a9a-f53e-4aee-a7e7-8562aba4f654",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12345)\n",
    "dataset = dataset.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fc4a91e-5b54-49a2-9478-96f9daaec0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74470, 9309, 93087)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_len, test_len = round(len(dataset)*.80), round(len(dataset)*.10) \n",
    "train_len, test_len, round(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcba371c-453e-4f46-82e2-a8d6027fe6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 74470\n",
      "Number of test graphs: 9309\n",
      "Number of validation graphs: 9308\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset[:train_len]\n",
    "test_dataset = dataset[train_len:train_len+test_len]\n",
    "val_dataset = dataset[train_len+test_len:]\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')\n",
    "print(f'Number of validation graphs: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "72a25bf8-de8f-40b8-973f-b1c9ba50e227",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=dataset.num_classes, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=dataset.num_classes, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ad01c07-0084-41b4-a096-7610e672171b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (emb): AtomEncoder(\n",
      "    (atom_embedding_list): ModuleList(\n",
      "      (0): Embedding(119, 17)\n",
      "      (1): Embedding(5, 17)\n",
      "      (2-3): 2 x Embedding(12, 17)\n",
      "      (4): Embedding(10, 17)\n",
      "      (5-6): 2 x Embedding(6, 17)\n",
      "      (7-8): 2 x Embedding(2, 17)\n",
      "    )\n",
      "  )\n",
      "  (conv1): GCNConv(9, 17)\n",
      "  (conv2): GCNConv(17, 17)\n",
      "  (conv3): GCNConv(17, 17)\n",
      "  (lin): Linear(in_features=17, out_features=17, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.emb = AtomEncoder(hidden_channels)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=dataset.num_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a66ebf1-6a60-4621-8a63-5228dd24213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(hidden_channels=dataset.num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "         data_x = data.x.to(torch.float32)\n",
    "         out = model(data_x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "         data_y = data.y.to(torch.float32)\n",
    "         loss = criterion(out, data_y)  # Compute the loss.\n",
    "         loss.backward()  # Derive gradients.\n",
    "         optimizer.step()  # Update parameters based on gradients.\n",
    "         optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "     model.eval()\n",
    "\n",
    "     correct = 0\n",
    "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "         data_x = data.x.to(torch.float32)\n",
    "         out = model(data_x, data.edge_index, data.batch)  \n",
    "         pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "         data_y = data.y.to(torch.float32)\n",
    "         correct += int((pred == data_y).sum())  # Check against ground-truth labels.\n",
    "     return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "for epoch in range(1, 171):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3338028b-5134-4efd-95ff-80a007df755d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a097af-c709-49b2-82a9-a5b85b664afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40322bb-e59f-4834-a7da-b56d8d130b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02000345-b971-4cf6-a709-976e04fafb88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0034f24-a12a-4a31-9157-92d4d905af42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(Net, self).__init__()\n",
    "        self.emb = AtomEncoder(hidden_channels)\n",
    "        self.conv1 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.emb(x)\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dacb989a-8f33-4f63-a873-2b1dfd6edd90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 17])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = dataset[0]\n",
    "net = Net(hidden_channels=64)\n",
    "out = net(test)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa198c70-c952-4c6b-a748-dcc5dbea23b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[27, 9], edge_index=[2, 60], edge_attr=[60, 3], smiles='Cc1cc(C)cc(N(C(=O)c2ccc3c(c2)OCO3)C2C=CS(=O)(=O)C2)c1', y=[1, 17])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ba9187-a27f-4e34-8b89-c3a2ca08a463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa06529e-cc37-4470-b9fb-e4fda96e275b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "301878c6-6cf3-4cfd-b5b9-10801b48144c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (64) must match the size of tensor b (17) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m171\u001b[39m):\n\u001b[1;32m     31\u001b[0m     train()\n\u001b[0;32m---> 32\u001b[0m     train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     test_acc \u001b[38;5;241m=\u001b[39m test(test_loader)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[42], line 26\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m     24\u001b[0m     pred \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Use the class with highest probability.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     data_y \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 26\u001b[0m     correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_y\u001b[49m)\u001b[38;5;241m.\u001b[39msum())  \u001b[38;5;66;03m# Check against ground-truth labels.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m correct \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(loader\u001b[38;5;241m.\u001b[39mdataset)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (17) at non-singleton dimension 1"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50da4ae-3667-4a54-a936-3404c8a7f232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6f6325-e04b-4876-9b23-0d74d482d048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00f54c1-fc33-4909-8be4-a8c06deeaf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_point = torch_geometric.data.Data(x=dataset.x, edge_index=dataset.edge_index, y=dataset.y)\n",
    "data_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27014008-95b3-4dc5-b48d-3d4202e5cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "data_point.train_mask = torch.Tensor( [:train_len] )  # [...] is of length y\n",
    "training_data.append(data_point)   \n",
    "\n",
    "#val\n",
    "data_point.test_mask = torch.Tensor( [train_len:train_len+test_len] )  # [...] is of length y\n",
    "test_data.append(data_point)   \n",
    "\n",
    "#test\n",
    "data_point.val_mask = torch.Tensor( [train_len+test_len:] )  # [...] is of length y\n",
    "val_data.append(data_point)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fec5d1d-759e-4d27-91c6-989ba0d3ec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b3a7e5-d7d1-4a1c-9757-83a7f957c132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb83a908-c047-4feb-bc31-52fd1a0a8d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9186f454-a759-4043-97f1-639bc2ae1f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = round(len(dataset)*.75)\n",
    "train_dataset = dataset[:train_len]\n",
    "test_dataset = dataset[train_len:]\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdf18f6-3531-4091-be69-a3c94b836d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "for step, data in enumerate(train_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e2c2d9-e795-4826-87fa-ec82d27ec79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchs = round(len(train_dataset)/64)\n",
    "batchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f04445e-40df-4ea3-bc88-206736f0d810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print first element\n",
    "print(f'Graph: {dataset[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2841f964-ea36-4feb-867c-e8e8ae1bb647",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = to_dense_adj(data.edge_index)[0].numpy().astype(int)\n",
    "print(f'A = {A.shape}')\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933ab272-0b9a-4ed8-a1cf-1377219e3733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_networkx\n",
    "nx.draw(to_networkx(dataset[0]),with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7754764b-09d2-477f-8c00-ab074c4facae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.gcn = GCNConv(dataset.num_features, 3)\n",
    "        self.out = Linear(3, dataset.num_classes)\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.gcn(x, edge_index).relu()\n",
    "        z = self.out(h)\n",
    "        return h, z\n",
    "model = GCN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de372f0-d7b2-473a-ab43-95ce70dcb5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad8816d-ed27-4e87-a413-1f8f762b075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "def accuracy(pred_y, y):\n",
    "    return (pred_y == y).sum() / len(y)\n",
    "# Data for animations\n",
    "embeddings = []\n",
    "losses = []\n",
    "accuracies = []\n",
    "outputs = []\n",
    "# Training loop\n",
    "for epoch in range(201):\n",
    "    # Clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    h, z = model(data.x, data.edge_index)\n",
    "    # Calculate loss function\n",
    "    loss = criterion(z, data.y)\n",
    "    # Calculate accuracy\n",
    "    acc = accuracy(z.argmax(dim=1), data.y)\n",
    "    # Compute gradients\n",
    "    loss.backward()\n",
    "    # Tune parameters\n",
    "    optimizer.step()\n",
    "    # Store data for animations\n",
    "    embeddings.append(h)\n",
    "    losses.append(loss)\n",
    "    accuracies.append(acc)\n",
    "    outputs.append(z.argmax(dim=1))\n",
    "    # Print metrics every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch:>3} | Loss: {loss:.2f} | Acc: {acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6db465b-358c-4ca3-84bf-ca0cbed8364e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0896a73-5768-4c07-9648-dd1d20418735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c96dc-3372-4fe8-b9dc-d78894491907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
